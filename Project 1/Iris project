Iris Flowers Classification ML Project : 


INTRODUCTION

Machine learning (ML) is a type of artificial intelligence (AI) that allows software applications to become more accurate at predicting outcomes without being explicitly programmed to do so. Machine learning algorithms use historical data as input to predict new output values.

Following are the steps involved in creating a well-defined ML project:
1] Understand and define the problem
2] Prepare the data
3] Explore and Analyse the data
4] Apply the algorithms
5] Reduce the errors
6] Predict the result

To understand various machine learning algorithms let us use the Iris data set, one of the most famous datasets available.


Iris Species Prediction

The Iris dataset was used in R.A. Fisher's classic 1936 paper which included 50 data of each species.
In this kernel we will use the dataset to predict the flower in 3 types of species namely: Setosa,Versicolor,Virginica using-
1.SepalLengthCm
2.SepalWidthCm
3.PetalLengthCm
4.PetalWidthCm
We would be using various Machine Learning techniques to predict the Iris Species in the kernel.

The Kernel is divided into:
1.Importing Libraries
2.Visualisation Techniques
3.Building Models
4.Model Performance.


Preview of data:
There are 150 observations with 4 features each (sepal length, sepal width, petal length, petal width).
There are no null values.
There are 50 observations of each species (setosa, versicolor, virginica).

Data Visualization
After graphing the features in a pair plot, it is clear that the relationship between pairs of features of an iris-setosa (in blue) is distinctly different from those of the other two species.
There is some overlap in the pairwise relationships of the other two species, iris-versicolor (brown) and iris-virginica (green).
Train and test on the same dataset
This method is not suggested since the end goal is to predict iris species using a dataset the model has not seen before.
There is also a risk of overfitting the training data.
 
Split the dataset into a training set and a testing set

Advantages
By splitting the dataset  into two separate sets, we can train using one set and test using another.
This ensures that we won't use the same observations in both sets.
More flexible and faster than creating a model using all of the dataset for training.

Disadvantages
The accuracy scores for the testing set can vary depending on what observations are in the set.

Notes
The accuracy score of the models depends on the observations in the testing set, which is determined by decision tree,Logistic regression,Naive boys .
As a model's complexity increases, the training accuracy (accuracy you get when you train and test the model on the same data) increases.
If a model is too complex or not complex enough, the testing accuracy is lower.
